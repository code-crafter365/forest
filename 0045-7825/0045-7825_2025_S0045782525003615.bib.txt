@article{THAKOLKARAN2025118089,
title = {Can KAN CANs? Input-convex Kolmogorov-Arnold Networks (KANs) as hyperelastic constitutive artificial neural networks (CANs)},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {443},
pages = {118089},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118089},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525003615},
author = {Prakash Thakolkaran and Yaqi Guo and Shivam Saini and Mathias Peirlinck and Benjamin Alheit and Siddhant Kumar},
keywords = {Constitutive modeling, Unsupervised learning, Hyperelasticity, Kolmogorov-arnold network, Convexity},
abstract = {Traditional constitutive models rely on hand-crafted parametric forms with limited expressivity and generalizability, while neural network-based models can capture complex material behavior but often lack interpretability. To balance these trade-offs, we present monotonic Input-Convex Kolmogorov-Arnold Networks (ICKANs) for learning polyconvex hyperelastic constitutive laws. ICKANs leverage the Kolmogorov-Arnold representation, decomposing the model into compositions of trainable univariate spline-based activation functions for rich expressivity. We introduce trainable monotonic input-convex splines within the KAN architecture, ensuring physically admissible polyconvex models for isotropic compressible hyperelasticity. The resulting models are both compact and interpretable, enabling explicit extraction of analytical constitutive relationships through a monotonic input-convex symbolic regression technique. Through unsupervised training on full-field strain data and limited global force measurements, ICKANs accurately capture nonlinear stress–strain behavior across diverse strain states. Finite element simulations of unseen geometries with trained ICKAN hyperelastic constitutive models confirm the framework’s robustness and generalization capability.}
}