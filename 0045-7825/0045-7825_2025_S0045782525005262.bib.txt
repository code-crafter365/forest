@article{YANG2025118254,
title = {Data-efficient deep operator network for unsteady flow: A multi-fidelity approach with physics-guided subsampling},
journal = {Computer Methods in Applied Mechanics and Engineering},
volume = {446},
pages = {118254},
year = {2025},
issn = {0045-7825},
doi = {https://doi.org/10.1016/j.cma.2025.118254},
url = {https://www.sciencedirect.com/science/article/pii/S0045782525005262},
author = {Sunwoong Yang and Youngkyu Lee and Namwoo Kang},
keywords = {Deep operator networks, Multi-fidelity modeling, Transfer learning, Physics-guided subsampling, Small dataset, Spatio-temporal flow prediction},
abstract = {This study presents an enhanced multi-fidelity deep operator network (DeepONet) framework for efficient spatio-temporal flow field prediction, with particular emphasis on practical scenarios where high-fidelity data is scarce. We introduce several key innovations to improve the frameworkâ€™s efficiency and accuracy. First, we enhance the DeepONet architecture by incorporating a merge network that enables more complex feature interactions between operator and spatio-temporal coordinates, achieving a 50.4 % reduction in prediction error compared to traditional dot-product operations. We further optimize the architecture through temporal positional encoding and point-based subsampling strategies, achieving a 7.57 % improvement in prediction accuracy while reducing training time by 96 %. Building upon this foundation, we develop a transfer learning-based multi-fidelity framework that leverages knowledge from pre-trained low-fidelity models to guide high-fidelity predictions. Our approach freezes the pre-trained branch and trunk networks while making only the merge network trainable during high-fidelity training, preserving valuable low-fidelity representations while efficiently adapting to high-fidelity features. Through systematic investigation, we demonstrate that this fine-tuning strategy not only outperforms linear probing and full-tuning alternatives but also surpasses conventional multi-fidelity frameworks by up to 76 %, while achieving up to 43.7 % improvement in prediction accuracy compared to single-fidelity training. As another core contribution, we introduce a physics-guided subsampling approach, which strategically selects high-fidelity training spatial points based on temporal dynamics identified by pre-trained low-fidelity models. This physics-guided subsampling strategy demonstrates remarkable effectiveness, achieving prediction accuracy comparable to a baseline model while reducing the high-fidelity sample requirement by 40 %. The robustness of these contributions, particularly our proposed MF-DeepONet framework and time-derivative subsampling, is further validated on a second, more complex dataset where they continue to demonstrate superior or highly competitive performance against conventional benchmarks. Through comprehensive experiments across multiple resolutions and two distinct datasets of increasing complexity, our enhanced framework demonstrates the potential to reduce the required high-fidelity dataset size while maintaining predictive accuracy.}
}