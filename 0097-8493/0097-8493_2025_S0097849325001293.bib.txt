@article{LI2025104288,
title = {VITON-DRR: Details retention virtual try-on via non-rigid registration},
journal = {Computers & Graphics},
volume = {131},
pages = {104288},
year = {2025},
issn = {0097-8493},
doi = {https://doi.org/10.1016/j.cag.2025.104288},
url = {https://www.sciencedirect.com/science/article/pii/S0097849325001293},
author = {Ben Li and Minqi Li and Jie Ren and Kaibing Zhang},
keywords = {Virtual try-on, Image deformation, Image synthesis, Non-rigid registration},
abstract = {Image-based virtual try-on aims to fit a target garment to a specific person image and has attracted extensive research attention because of its huge application potential in the e-commerce and fashion industries. To generate high-quality try-on results, accurately warping the clothing item to fit the human body plays a significant role, as slight misalignment may lead to unrealistic artifacts in the fitting image. Most existing methods warp the clothing by feature matching and thin-plate spline (TPS). However, it often fails to preserve clothing details due to self-occlusion, severe misalignment between poses, etc. To address these challenges, this paper proposes a detail retention virtual try-on method via accurate non-rigid registration (VITON-DRR) for diverse human poses. Specifically, we reconstruct a human semantic segmentation using a dual-pyramid-structured feature extractor. Then, a novel Deformation Module is designed for extracting the cloth key points and warping them through an accurate non-rigid registration algorithm. Finally, the Image Synthesis Module is designed to synthesize the deformed garment image and generate the human pose information adaptively. Compared with traditional methods, the proposed VITON-DRR can make the deformation of fitting images more accurate and retain more garment details. The experimental results demonstrate that the proposed method performs better than state-of-the-art methods. Our code is publicly available at https://github.com/minqili/VITON-DRR-main.}
}