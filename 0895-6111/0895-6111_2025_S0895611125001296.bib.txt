@article{PELLUET2025102620,
title = {Enhancing breast cancer screening: Unveiling explainable cross-view contributions in dual-view mammography with Sparse Bipartite Graphs Attention Networks},
journal = {Computerized Medical Imaging and Graphics},
volume = {125},
pages = {102620},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102620},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001296},
author = {Guillaume Pelluet and Mira Rizkallah and Mickael Tardy and Diana Mateus},
keywords = {Breast cancer screening, Dual-view mammography, Bipartite Graphs, Graph Attention Networks, Sparse attentive explanations},
abstract = {Medical imaging techniques like mammography enable early breast cancer detection and are part of regular screening programs. Typically, a mammogram exam involves two views of each breast, providing complementary information, but physicians rate the breast as a whole. Computer-Aided Diagnostic tools focus on detecting lesions in a single view, which is challenging due to high image resolution and varying scales of abnormalities. The projective nature of the two views and different acquisition protocols add complexity to dual-view analysis. To address these challenges, we propose a Graph Neural Network approach that models image information at multiple scales and the complementarity of the two views. To this end, we rely on a superpixel decomposition, assigning hierarchical features to superpixels, designing a dual-view graph to share information, and introducing a modified Sparse Graph Attention Layer to keep relevant dual-view relations. This improves interpretability of decisions and avoids the need to register pairs of views under strong deformations. Our model is trained with a fully supervised approach and evaluated on public and private datasets. Experiments demonstrate state-of-the-art classification and detection performance on Full Field Digital Mammographies, achieving a breast-wise AUC of 0.96 for the INbreast dataset, a sensitivity of 0.97 with few false positives per image (0.33), and a case-wise AUC of 0.92 for the VinDr dataset. This study presents a Sparse Graph Attention method for dual-view mammography analysis, generating meaningful explanations that radiologists can interpret. Extensive evaluation shows the relevance of our approach in breast cancer detection and classification.}
}