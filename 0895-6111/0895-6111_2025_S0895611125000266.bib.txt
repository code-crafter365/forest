@article{LIU2025102517,
title = {A unified approach to medical image segmentation by leveraging mixed supervision and self and transfer learning (MIST)},
journal = {Computerized Medical Imaging and Graphics},
volume = {122},
pages = {102517},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102517},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125000266},
author = {Jianfei Liu and Sayantan Bhadra and Omid Shafaat and Pritam Mukherjee and Christopher Parnell and Ronald M. Summers},
keywords = {Dual-branch network, Adipose tissue, Muscle, NnUNet, Multi-class segmentation},
abstract = {Medical image segmentation is important for quantitative disease diagnosis and treatment but relies on accurate pixel-wise labels, which are costly, time-consuming, and require domain expertise. This work introduces MIST (MIxed supervision, Self, and Transfer learning) to reduce manual labeling in medical image segmentation. A small set of cases was manually annotated (“strong labels”), while the rest used automated, less accurate labels (“weak labels”). Both label types trained a dual-branch network with a shared encoder and two decoders. Self-training iteratively refined weak labels, and transfer learning reduced computational costs by freezing the encoder and fine-tuning the decoders. Applied to segmenting muscle, subcutaneous, and visceral adipose tissue, MIST used only 100 manually labeled slices from 20 CT scans to generate accurate labels for all slices of 102 internal scans, which were then used to train a 3D nnU-Net model. Using MIST to update weak labels significantly improved nnU-Net segmentation accuracy compared to training directly on strong and weak labels. Dice similarity coefficient (DSC) increased for muscle (89.2 ± 4.3% to 93.2 ± 2.1%), subcutaneous (75.1 ± 14.4% to 94.2 ± 2.8%), and visceral adipose tissue (66.6 ± 16.4% to 77.1 ± 19.0% ) on an internal dataset (p<.05). DSC improved for muscle (80.5 ± 6.9% to 86.6 ± 3.9%) and subcutaneous adipose tissue (61.8 ± 12.5% to 82.7 ± 11.1%) on an external dataset (p<.05). MIST reduced the annotation burden by 99%, enabling efficient, accurate pixel-wise labeling for medical image segmentation. Code is available at https://github.com/rsummers11/NIH_CADLab_Body_Composition.}
}