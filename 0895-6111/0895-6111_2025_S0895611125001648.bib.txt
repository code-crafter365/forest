@article{HUANG2025102655,
title = {A CNN-Transformer fusion network for Diabetic retinopathy image classification},
journal = {Computerized Medical Imaging and Graphics},
volume = {126},
pages = {102655},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102655},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001648},
author = {Xuan Huang and Zhuang Ai and Chongyang She and Qi Li and Qihao Wei and Sha Xu and Yaping Lu and Fanxin Zeng},
keywords = {Diabetic retinopathy, Attention mechanism, Transformer, Image classification, Feature fusion},
abstract = {Diabetic retinopathy (DR) is a leading cause of blindness worldwide, yet current diagnosis relies on labor-intensive and subjective fundus image interpretation. Here we present a convolutional neural network-transformer fusion model (DR-CTFN) that integrates ConvNeXt and Swin Transformer algorithms with a lightweight attention block (LAB) to enhance feature extraction. To address dataset imbalance, we applied standardized preprocessing and extensive image augmentation. On the Kaggle EyePACS dataset, DR-CTFN outperformed ConvNeXt and Swin Transformer in accuracy by 3.14% and 8.39%, while also achieving a superior area under the curve (AUC) by 1% and 26.08%. External validation on APTOS 2019 Blindness Detection and a clinical DR dataset yielded accuracies of 84.45% and 85.31%, with AUC values of 95.22% and 95.79%, respectively. These results demonstrate that DR-CTFN enables rapid, robust, and precise DR detection, offering a scalable approach for early diagnosis and prevention of vision loss, thereby enhancing the quality of life for DR patients.}
}