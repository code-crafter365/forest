@article{LI2025102660,
title = {Efficient frequency-decomposed transformer via large vision model guidance for surgical image desmoking},
journal = {Computerized Medical Imaging and Graphics},
volume = {126},
pages = {102660},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102660},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001697},
author = {Jiaao Li and Diandian Guo and Youyu Wang and Yanhui Wan and Long Ma and Jialun Pei},
keywords = {Surgical image restoration, Desmoking, Fourier Transform, SAM},
abstract = {Surgical image restoration plays a vital clinical role in improving visual quality during surgery, particularly in minimally invasive procedures where the operating field is frequently obscured by surgical smoke. However, surgical image desmoking still has limited progress in algorithm development and customized learning strategies. In this regard, this work focuses on the task of desmoking from both theoretical and practical perspectives. First, we analyze the intrinsic characteristics of surgical smoke degradation: (1) spatial localization and dynamics, (2) distinguishable frequency-domain patterns, and (3) the entangled representation of anatomical content and degradative artifacts. These observations motivated us to propose an efficient frequency-aware Transformer framework, namely SmoRestor, which aims to separate and restore true anatomical structures from complex degradations. Specifically, we introduce a high-order Fourier-embedded neighborhood attention transformer that enhances the modelâ€™s ability to capture structured degradation patterns across both spatial and frequency domains. Besides, we utilize the semantic priors encoded by large vision models to disambiguate content from degradation through targeted guidance. Moreover, we propose an innovative transfer learning paradigm that injects knowledge from large models to the main network, enabling it to effectively distinguish meaningful content from ambiguous corruption. Experimental results on both public and in-house datasets demonstrate substantial improvements in quantitative performance and visual quality. The source code will be available.}
}