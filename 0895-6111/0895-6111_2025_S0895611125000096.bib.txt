@article{XU2025102500,
title = {Contrastive learning in brain imaging},
journal = {Computerized Medical Imaging and Graphics},
volume = {121},
pages = {102500},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102500},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125000096},
author = {Xiaoyin Xu and Stephen T.C. Wong},
keywords = {Contrastive learning, Brain imaging, Unsupervised learning, Brain tumor, Alzheimer's disease},
abstract = {Contrastive learning is a type of deep learning technique trying to classify data or examples without requiring data labeling. Instead, it learns about the most representative features that contrast positive and negative pairs of examples. In literature of contrastive learning, terms of positive examples and negative examples do not mean whether the examples themselves are positive or negative of certain characteristics as one might encounter in medicine. Rather, positive examples just mean that the examples are of the same class, while negative examples mean that the examples are of different classes. Contrastive learning maps data to a latent space and works under the assumption that examples of the same class should be located close to each other in the latent space; and examples from different classes would locate far from each other. In other words, contrastive learning can be considered as a discriminator that tries to group examples of the same class together while separating examples of different classes from each other, preferably as far as possible. Since its inception, contrastive learning has been constantly evolving and can be realized as self-supervised, semi-supervised, or unsupervised learning. Contrastive learning has found wide applications in medical imaging and it is expected it will play an increasingly important role in medical image processing and analysis.}
}