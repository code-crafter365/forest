@article{ZHOU2025102597,
title = {AMeta-FD: Adversarial Meta-learning for Few-shot retinal OCT image Despeckling},
journal = {Computerized Medical Imaging and Graphics},
volume = {124},
pages = {102597},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102597},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001065},
author = {Yi Zhou and Tao Peng and Thiara Sana Ahmed and Fei Shi and Weifang Zhu and Dehui Xiang and Leopold Schmetterer and Jianxin Jiang and Bingyao Tan and Xinjian Chen},
keywords = {Meta-learning, OCT image despeckling, Generative adversarial network},
abstract = {Speckle noise in Optical coherence tomography (OCT) images compromises the performance of image analysis tasks such as retinal layer boundary detection. Deep learning algorithms have demonstrated the advantage of being more cost-effective and robust compared to hardware solutions and conventional image processing algorithms. However, these methods usually require large training datasets which is time-consuming to acquire. This paper proposes a novel method called Adversarial Meta-learning for Few-shot raw retinal OCT image Despeckling (AMeta-FD) to reduce speckle noise in OCT images. Our method involves two training phases: (1) adversarial meta-training on synthetic noisy OCT image pairs, and (2) fine-tuning with a small set of raw-clean image pairs containing speckle noise. Additionally, we introduce a new suppression loss to reduce the contribution of non-tissue pixels effectively. The ground truth involved in this study is generated by registering and averaging multiple repeated images. AMeta-FD requires only 60 raw-clean image pairs, which constitute about 12% of whole training dataset, yet it achieves performance on par with traditional transfer training that utilize the entire training dataset. Extensive evaluations show that in terms of signal-to-noise ratio (SNR), AMeta-FD surpasses traditional non-learning-based despeckling methods by at least 15 dB. It also outperforms the recent meta-learning-based image denoising method, Few-Shot Meta-Denoising (FSMD), by 11.01 dB, and exceeds our previous best method by 3 dB. The code for AMeta-FD is available at https://github.com/Zhouyi-Zura/AMeta-FD.}
}