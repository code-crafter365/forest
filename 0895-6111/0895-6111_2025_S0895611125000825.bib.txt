@article{WU2025102573,
title = {A segmentation network based on CNNs for identifying laryngeal structures in video laryngoscope images},
journal = {Computerized Medical Imaging and Graphics},
volume = {124},
pages = {102573},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102573},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125000825},
author = {Jinjing Wu and Wenhui Guo and Zhanheng Chen and Huixiu Hu and Houfeng Li and Ying Zhang and Jing Huang and Long Liu and Zhenghao Xu and Tianying Xu and Miao Zhou and Chenglong Zhu and Haipo Cui and Wenyun Xu and Zui Zou},
keywords = {Visual laryngoscope, Intubation, Semantic segmentation, Convolutional neural network, Deep learning, Artificial intelligence},
abstract = {Video laryngoscopes have become increasingly vital in tracheal intubation, providing clear imaging that significantly improves success rates, especially for less experienced clinicians. However, accurate recognition of laryngeal structures remains challenging, which is critical for successful first-attempt intubation in emergency situations. This paper presents MPE-UNet, a deep learning model designed for precise segmentation of laryngeal structures from video laryngoscope images, aiming to assist clinicians in performing tracheal intubation more accurately and efficiently. MPE-UNet follows the classic U-Net architecture, which features an encoder–decoder structure and enhances it with advanced modules and innovative techniques at every stage. In the encoder, we designed an improved multi-scale feature extraction module, which better processes complex throat images. Additionally, a pyramid fusion attention module was incorporated into the skip connections, enhancing the model’s ability to capture details by dynamically weighting and merging features from different levels. Moreover, a plug-and-play attention mechanism module was integrated into the decoder, further refining the segmentation process by focusing on important features. The experimental results show that the performance of the proposed method outperforms state-of-the-art methods.}
}