@article{WANG2025102601,
title = {A VVBP data-based pancreatic lesion detection model with noncontrast CT},
journal = {Computerized Medical Imaging and Graphics},
volume = {124},
pages = {102601},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102601},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001107},
author = {Wanzhen Wang and Chenjie Zhou and Xiaoying Chen and Geye Tang and Jianhua Ma and Yi Gao and Shulong Li},
keywords = {Pancreatic cancer, Lesion detection, VVBP data, Noncontrast CT, Cross-attention mechanism},
abstract = {Pancreatic cancer (PC) is one of the most aggressive cancers. Noncontrast CT (NCCT) offers a suitable platform for developing early detection algorithms to improve early diagnosis, prognosis, and overall survival rates. The view-by-view back-projection (VVBP) data from the filtered back-projection algorithm reveal that information across different views is correlated, complementary, and often redundant, which may be compressed or overlooked. These data can be interpreted as a 3D decomposition of 2D images, providing a richer representation than individual images. Leveraging these advantages, an NCCT-based pancreatic lesion detection model using VVBP data is proposed. This novel method is designed to process VVBP data into N sparse images. The model comprises three main modules: ResNet50-Unet, which extracts primary features from each sparse image and compensates for information loss from simulated VVBP data by a reconstruction branch; a novel multicross channel-spatial-attention (mcCSA) mechanism, which fuses primary features and facilitates feature interaction and learning in VVBP data; and Faster R-CNN with the weighted candidate bounding box fusion (WCBF) technique, which generates advanced region proposal generation based on integrated VVBP data. The model showed optimal performance when N = 3, outperforming competing methods across most metrics, with recalls of 75.7 % and 90.5 %, precisions of 41.4 % and 66.9 %, F1 scores of 73.5 % and 76.9 %, F2 scores of 64.9 % and 84.5 %, and AP50 values of 56.2 % and 76.9 % at the image and patient levels, respectively. The 90.5 % patient-level recall underscores the model’s clinical potential as an AI tool for early PC detection and screening.}
}