@article{JEFFREY2025102630,
title = {Inference time correction based on confidence and uncertainty for improved deep-learning model performance and explainability in medical image classification},
journal = {Computerized Medical Imaging and Graphics},
volume = {125},
pages = {102630},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102630},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001399},
author = {Joel Jeffrey and Ashwin RajKumar and Sudhanshu Pandey and Lokesh Bathala and Phaneendra K. Yalavarthy},
keywords = {Explainable artificial intelligence, Interpretable artificial intelligence, Confidence, Entropy, Uncertainty, Deep learning},
abstract = {The major challenge faced by artificial intelligence (AI) models for medical image analysis is the class imbalance of training data and limited explainability. This study introduces a Confidence and Entropy-based Uncertainty Thresholding Algorithm (CEbUTAl), which is a novel post-processing method, designed to enhance both model performance and explainability. CEbUTAl modifies model predictions during inference, based on uncertainty and confidence measures, to improve classification in scenarios with class imbalance. CEbUTAlâ€™s inference-time correction addresses explainability, while simultaneously improving performance, contrary to the prevailing notion that explainability necessitates a compromise in performance. The algorithm was evaluated across five medical imaging tasks: intracranial hemorrhage detection, optical coherence tomography analysis, breast cancer detection, carpal tunnel syndrome detection, and multi-class skin lesion classification. Results demonstrate that CEbUTAl improves accuracy by approximately 5% and increases sensitivity across multiple deep learning architectures, loss functions, and tasks. Comparative studies indicate that CEbUTAl outperforms state-of-the-art methods in addressing class imbalance and quantifying uncertainty. The model-agnostic, task-agnostic and post-processing nature of CEbUTAl makes it appealing for enhancing both performance and trustworthiness in medical image analysis. This study provides a generalizable approach to mitigate biases arising from class imbalance, while improving the explainability of AI models, thus increasing their utility in clinical practice.}
}