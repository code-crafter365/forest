@article{IRFAN2025102507,
title = {One-shot learning for generalization in medical image classification across modalities},
journal = {Computerized Medical Imaging and Graphics},
volume = {122},
pages = {102507},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102507},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125000163},
author = {Muhammad Irfan and Ijaz Ul Haq and Khalid Mahmood Malik and Khan Muhammad},
keywords = {Few Shot Learning, One Shot Learning, Classification, Medical image analysis, Computer aided diagnosis},
abstract = {Generalizability is one of the biggest challenges hindering the advancement of medical sensing technologies across multiple imaging modalities. This issue is further impaired when the imaging data is limited in scope or of poor quality. To tackle this, we propose a generalized and robust, lightweight one-shot learning method for medical image classification across various imaging modalities, including X-ray, microscopic, and CT scans. Our model introduces a collaborative one-shot training (COST) approach, incorporating both meta-learning and metric-learning. This approach allows for effective training on only one image per class. To ensure generalization with fewer epochs, we employ gradient generalization at dense and fully connected layers, utilizing a lightweight Siamese network with triplet loss and shared parameters. The proposed model was evaluated on 12 medical image datasets from MedMNIST2D, achieving an average accuracy of 91.5 % and area under the curve (AUC) of 0.89, outperforming state-of-the-art models such as ResNet-50 and AutoML by over 10 % on certain datasets. Further, in the OCTMNIST dataset, our model achieved an AUC of 0.91 compared to ResNet-50’s 0.77. Ablation studies further validate the superiority of our approach, with the COST method showing significant improvement in convergence speed and accuracy when compared to traditional one-shot learning setups. Additionally, our model’s lightweight architecture requires only 0.15 million parameters, making it well-suited for deployment on resource-constrained devices.}
}