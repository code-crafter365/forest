@article{GONG2025102581,
title = {MedBLIP: A multimodal method of medical question-answering based on fine-tuning large language model},
journal = {Computerized Medical Imaging and Graphics},
volume = {124},
pages = {102581},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102581},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125000904},
author = {Lejun Gong and Jiaming Yang and Shengyuan Han and Yimu Ji},
keywords = {Large language model, Question answering, Multi-modal, Fine-tune, Medical images, Medical language generation tasks},
abstract = {Medical visual question answering is crucial for effectively interpreting medical images containing clinically relevant information. This study proposes a method called MedBLIP (Medical Treatment Bootstrapping Language-Image Pretraining) to tackle visual language generation tasks related to chest X-rays in the medical field. The method combine an image encoder with a large-scale language model, and effectively generates medical question-answering text through a strategy of freezing the image encoder based on the BLIP-2 model. Firstly, chest X-ray images are preprocessed, and an image sample generation algorithm is used to enhance the text data of doctor-patient question-answering, thereby increasing data diversity. Then, a multi-layer convolutional image feature extractor is introduced to better capture the feature representation of medical images. During the fine-tuning process of the large language generation model, a new unfreezing strategy is proposed, which is to unfreeze different proportions of the weights of the fully connected layer to adapt to the data in the medical field. The image feature extractor is responsible for extracting key features from images, providing the model with rich visual information, while the text feature extractor accurately captures the essential requirements of the user's question. Through their synergistic interaction, the model can more effectively integrate medical images and user inquiries, thereby generating more accurate and relevant output content. The experimental results show that unfreezing 31.25 % of the weights of the fully connected layer can significantly improve the performance of the model, with ROUGE-L reaching 66.12 %, and providing a more accurate and efficient answer generation solution for the medical field. The method of this study has potential applications in the field of medical language generation tasks. Although the proposed model cannot yet fully replace human radiologists, it plays an indispensable role in improving diagnostic efficiency, assisting decision-making, and supporting medical research. With continuous technological advancements, the model's performance will be further enhanced, and its application value in the medical field will become even more significant. The algorithm implementation can be obtained from https://github.com/JiminFohill/MedicalChat.git.}
}