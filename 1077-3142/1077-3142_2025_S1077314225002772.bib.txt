@article{XIONG2025104554,
title = {DiffuseDoc: Document geometric rectification via diffusion model},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104554},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104554},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002772},
author = {Wenfei Xiong and Huabing Zhou and Yanduo Zhang and Tao Lu and Jiayi Ma},
keywords = {Document geometric rectification, Conditional diffusion network, Deep learning, Dataset},
abstract = {Document images captured by sensors often suffer from intricate geometric distortions, hindering readability and impeding downstream document analysis tasks. While deep learning-based methods for document geometric rectification have shown promising results, their training heavily relies on high quality ground truth for the mapping field, resulting in challenging and expensive dataset creation. To address this issue, we propose DiffuseDoc, a novel framework for document image geometric rectification based on the diffusion model. Unlike existing methods, the training process of DiffuseDoc only requires pairs of distorted and distortion-free images, eliminating the need for ground truth mapping field supervision. Specifically, DiffuseDoc consists of two primary components: the geometric rectification module and the conditional diffusion module. By jointly training the two components, the rectification results are optimized while simultaneously learning the latent feature distribution of the distortion-free image. Also, we contribute the DocReal dataset, comprising document images captured by diverse high-resolution sensors in real-world scenarios, alongside their corresponding scanned versions. Extensive evaluations demonstrate that DiffuseDoc achieves state-of-the-art performance on both the Doc-U-Net benchmark and DocReal datasets.}
}