@article{ZHANG2025104431,
title = {An effective CNN and Transformer fusion network for camouflaged object detection},
journal = {Computer Vision and Image Understanding},
volume = {259},
pages = {104431},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104431},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001547},
author = {Dongdong Zhang and Chunping Wang and Huiying Wang and Qiang Fu and Zhaorui Li},
keywords = {CNN, Transformer, Camouflage object detection, Feature fusion},
abstract = {Camouflage object detection aims to identify concealed objects in images. Global context and local spatial details are crucial for this task. Convolutional neural network (CNN) excels at capturing fine-grained local features, while Transformer is adept at modeling global contextual information. To leverage their respective strengths, we propose a novel CNN-Transformer fusion network (CTF-Net) for COD to achieve more accurate detection. Our approach employs parallel CNN and Transformer branches as an encoder to extract complementary features. We then propose a cross-domain fusion module (CDFM) to fuse these features with cross-modulation. Additionally, we develop a boundary-aware module (BAM) that combines low-level edge details with high-level global context to extract camouflaged object edge features. Furthermore, we design a feature enhancement module (FEM) to mitigate background and noise interference during cross-layer feature fusion, thereby highlighting camouflaged object regions for precise predictions. Extensive experiments show that CTF-Net outperforms the existing 16 state-of-the-art methods on four widely-used COD datasets. Especially, compared with all the comparison models, CTF-Net significantly improves the performance by âˆ¼5.1% (F-measure) on the NC4K dataset, showing that CTF-Net could accurately detect camouflaged objects. Our code is publicly available at https://github.com/zcc0616/CTF-Net.}
}