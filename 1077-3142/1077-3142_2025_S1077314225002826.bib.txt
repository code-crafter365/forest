@article{PENNISI2025104559,
title = {DiffExplainer: Towards cross-modal global explanations with diffusion models},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104559},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104559},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002826},
author = {Matteo Pennisi and Giovanni Bellitto and Simone Palazzo and Isaak Kavasidis and Mubarak Shah and Concetto Spampinato},
keywords = {Activation maximization, Explainability, Diffusion models},
abstract = {We present DiffExplainer, a novel framework that, leveraging language-vision models, enables multimodal global explainability. DiffExplainer employs diffusion models conditioned on optimized text prompts, synthesizing images that maximize class outputs and hidden features of a classifier, thus providing a visual tool for explaining decisions. Moreover, the analysis of generated visual descriptions allows for automatic identification of biases and spurious features, as opposed to traditional methods that often rely on manual intervention. The cross-modal transferability of language-vision models also enables the possibility to describe decisions in a more human-interpretable way, i.e., through text. We conduct comprehensive experiments demonstrating the effectiveness of DiffExplainer on (1) the generation of high-quality images explaining model decisions, surpassing existing activation maximization methods, and (2) the automated identification of biases and spurious features.}
}