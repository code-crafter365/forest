@article{CHEN2025104380,
title = {Underwater image quality evaluation via deep meta-learning: Dataset and objective method},
journal = {Computer Vision and Image Understanding},
volume = {257},
pages = {104380},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104380},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001031},
author = {Tianhai Chen and Xichen Yang and Tianshu Wang and Nengxin Li and Shun Zhu and Xiaobo Shen},
keywords = {Underwater image dataset, Image quality assessment, Meta-learning, Multi-scale},
abstract = {The degradation of underwater image quality due to complex environments affects the effectiveness of the application, making accurate quality assessment crucial. However, existing Underwater Image Quality Assessment (UIQA) methods lack sufficient reliable data. To address this, we construct the DART2024 dataset, containing 1,000 raw images and 10,000 distorted images generated by 10 enhancement methods, covering diverse underwater scenarios. We propose a novel UIQA method that weights original images via gradient maps, highlights details, constructs a multi-scale deep neural network with perception, fusion, and prediction modules to describe quality characteristics, and designs a meta-learning framework for rapid adaptation to unknown distortions. The experimental results show that DART2024 is credible and meets the training requirements. Our method outperforms SOTA approaches in accuracy, stability, and convergence speed on DART2024 and other underwater datasets. It also shows higher applicability on natural scene datasets. The dataset and source code for the proposed method can be made available at https://github.com/dart-into/DART2024.}
}