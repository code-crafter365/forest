@article{THATIPELLI2025104371,
title = {Egocentric and exocentric methods: A short survey},
journal = {Computer Vision and Image Understanding},
volume = {257},
pages = {104371},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104371},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225000943},
author = {Anirudh Thatipelli and Shao-Yuan Lo and Amit K. Roy-Chowdhury},
keywords = {Egocentric, Exocentric, Ego-exo learning, Action recognition},
abstract = {Egocentric vision captures the scene from the point of view of the camera wearer while exocentric vision captures the overall scene context. Jointly modeling ego and exo views is crucial to developing next-generation AI agents. The community has regained interest in the field of egocentric vision. While the third-person view and first-person have been thoroughly investigated, very few works aim to study both synchronously. Exocentric videos contain many relevant signals that are transferrable to egocentric videos. This paper provides a timely overview of works combining egocentric and exocentric visions, a very new but promising research topic. We describe in detail the datasets and present a survey of the key applications of ego-exo joint learning, where we identify the most recent advances. With the presentation of the current status of the progress, we believe this short but timely survey will be valuable to the broad video-understanding community, particularly when multi-view modeling is critical.}
}