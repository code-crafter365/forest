@article{ZHANG2025104221,
title = {Leaf cultivar identification via prototype-enhanced learning},
journal = {Computer Vision and Image Understanding},
volume = {250},
pages = {104221},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104221},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224003023},
author = {Yiyi Zhang and Zhiwen Ying and Ying Zheng and Cuiling Wu and Nannan Li and Fangfang Wang and Jun Wang and Xianzhong Feng and Xiaogang Xu},
keywords = {Ultra-fine-grained visual classification, Leaf cultivar identification, Prototype-enhanced learning},
abstract = {Leaf cultivar identification, as a typical task of ultra-fine-grained visual classification (UFGVC), is facing a huge challenge due to the high similarity among different varieties. In practice, an instance may be related to multiple varieties to varying degrees, especially in the UFGVC datasets. However, deep learning methods trained on one-hot labels fail to reflect patterns shared across categories and thus perform poorly on this task. As an analogy to natural language processing (NLP), by capturing the co-relation between labels, label embedding can select the most informative words and neglect irrelevant ones when predicting different labels. Based on this intuition, we propose a novel method named Prototype-enhanced Learning (PEL), which is predicated on the assumption that label embedding encoded with the inter-class relationships would force the image classification model to focus on discriminative patterns. In addition, a new prototype update module is put forward to learn inter-class relations by capturing label semantic overlap and iteratively update prototypes to generate continuously enhanced soft targets. Prototype-enhanced soft labels not only contain original one-hot label information, but also introduce rich inter-category semantic association information, thus providing more effective supervision for deep model training. Extensive experimental results on 7 public datasets show that our method can significantly improve the performance on the task of ultra-fine-grained visual classification. The code is available at https://github.com/YIYIZH/PEL.}
}