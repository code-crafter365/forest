@article{ZHANG2025104430,
title = {Adaptive context mining for camouflaged object detection with scribble supervision},
journal = {Computer Vision and Image Understanding},
volume = {259},
pages = {104430},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104430},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001535},
author = {Dongdong Zhang and Chunping Wang and Huiying Wang and Qiang Fu and Zhaorui Li},
keywords = {Camouflaged object detection, Weakly supervised, Scribble, Contextual information, Polyp segmentation},
abstract = {Camouflaged object detection (COD) aims to find objects hidden in their surroundings, which has attracted extensive attention in recent years. Although fully supervised COD methods have made considerable progress in performance, they rely heavily on expensive pixel-level annotations. Scribble-based weakly supervised methods can effectively alleviate this problem, but they struggle to fully understand complex COD tasks and achieve outstanding performance due to limited information in the training data. In this paper, inspired by the human visual mechanism, we propose a novel framework for graffiti-based COD, named SCNet. This framework focuses on learning multi-scale context-aware features and employs a two-stage strategy for efficient detection. Specifically, we first adopt the improved Pyramid Visual Transformer (PVTv2) model as the backbone to extract multi-scale global contextual information. A neighbor-interactive decoder (NID) is then designed to coarsely localize potential object regions. Further, a refinement module (RM) is introduced to facilitate multi-scale information interaction and contextual information mining to refine the object regions. In addition, adaptive local camouflage coherence (ALCC) loss is devised to enhance the networkâ€™s adaptability to different complex scenarios. Experimental results on three benchmark COD datasets show that SCNet, which utilizes only scribble annotations without any pre- or post-processing, not only outperforms six state-of-the-art weakly supervised methods, but even surpasses some fully supervised COD methods. Moreover, SCNet achieves promising results in a COD-related task (polyp segmentation). The results of our method are available at https://github.com/zcc0616/SCNet.}
}