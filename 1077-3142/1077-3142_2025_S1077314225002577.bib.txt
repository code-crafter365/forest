@article{MAO2025104534,
title = {Gated-enhanced attention addition network for indoor RGB-D semantic segmentation},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104534},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104534},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002577},
author = {Chongchong Mao and Yongsheng Dong and Lintao Zheng and Ziang Jiao},
keywords = {RGB-D images, Multi-level features, Global feature attention, Gated-enhanced transformation block},
abstract = {In indoor RGB-D semantic segmentation tasks, although RGB images and depth images can provide complementary information, they often suffer from issues such as noise interference, incomplete data, and inconsistent information, which significantly impair the model’s ability to capture key information. So this can weaken model’s ability to extract key semantic and spatial information, ultimately leading to reduced segmentation accuracy. To alleviate these issues, this paper proposes a gated-enhanced attention addition network (GA2Net) for indoor RGB-D semantic segmentation. This network can utilize multi-level feature information while filtering and enhancing information from both RGB images and depth images. Specifically, the proposed GA2Net consists of two core components: the global feature extraction (GFE) block and a gated-enhanced transformation (GET) block. The GFE block enhances the external attention mechanism’s ability to uncover potential relationships across the entire dataset, helping the model better grasp global features; the gated-enhanced transformation block optimizes the expressive power of shallow and deep features by dynamically adjusting features in the spatial and channel dimensions through a combination of normalization and gating mechanisms. Extensive experiments show that our GA2Net achieves the better mIoU and accuracy on NYU-Depth V2 and SUN RGB-D.}
}