@article{BENAVENTLLEDO2025104560,
title = {Enhancing action recognition by leveraging the hierarchical structure of actions and textual context},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104560},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104560},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002838},
author = {Manuel Benavent-Lledo and David Mulero-Pérez and David Ortiz-Perez and Jose Garcia-Rodriguez and Antonis Argyros},
keywords = {Action recognition, Action hierarchies, Action context, Vision-language transformer},
abstract = {We propose a novel approach to improve action recognition by exploiting the hierarchical organization of actions and by incorporating contextualized textual information, including location and previous actions, to reflect the action’s temporal context. To achieve this, we introduce a transformer architecture tailored for action recognition that employs both visual and textual features. Visual features are obtained from RGB and optical flow data, while text embeddings represent contextual information. Furthermore, we define a joint loss function to simultaneously train the model for both coarse- and fine-grained action recognition, effectively exploiting the hierarchical nature of actions. To demonstrate the effectiveness of our method, we extend the Toyota Smarthome Untrimmed (TSU) dataset by incorporating action hierarchies, resulting in the Hierarchical TSU dataset, a hierarchical dataset designed for monitoring activities of the elderly in home environments. An ablation study assesses the performance impact of different strategies for integrating contextual and hierarchical data. Experimental results demonstrate that the proposed method consistently outperforms SOTA methods on the Hierarchical TSU dataset, Assembly101 and IkeaASM, achieving over a 17% improvement in top-1 accuracy.}
}