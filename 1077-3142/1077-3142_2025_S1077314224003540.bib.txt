@article{MALARZ2025104273,
title = {Gaussian Splatting with NeRF-based color and opacity},
journal = {Computer Vision and Image Understanding},
volume = {251},
pages = {104273},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104273},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224003540},
author = {Dawid Malarz and Weronika Smolak-Dyżewska and Jacek Tabor and Sławomir Tadeja and Przemysław Spurek},
keywords = {3D Gaussian Splatting, Rendering, Scene reconstruction, Neural rendering},
abstract = {Neural Radiance Fields (NeRFs) have demonstrated the remarkable potential of neural networks to capture the intricacies of 3D objects. NeRFs excel at producing strikingly sharp novel views of 3D objects by encoding the shape and color information within neural network weights. Recently, numerous generalizations of NeRFs utilizing generative models have emerged, expanding their versatility. In contrast, Gaussian Splatting (GS) offers a similar render quality with faster training and inference as it does not need neural networks to work. It encodes information about the 3D objects in the set of Gaussian distributions that can be rendered in 3D similarly to classical meshes. Unfortunately, GS is difficult to condition since its representation is fully explicit. To mitigate the caveats of both models, we propose a hybrid model Viewing Direction Gaussian Splatting (VDGS) that uses GS representation of the 3D object’s shape and NeRF-based encoding of opacity. Our model uses Gaussian distributions with trainable positions (i.e., means of Gaussian), shape (i.e., the covariance of Gaussian), opacity, and a neural network that takes Gaussian parameters and viewing direction to produce changes in the said opacity.As a result, our model better describes shadows, light reflections, and the transparency of 3D objects without adding additional texture and light components.}
}