@article{ZHANG2025104378,
title = {Guided progressive learning for room layout estimation: From pixel-level embeddings to refined depth maps},
journal = {Computer Vision and Image Understanding},
volume = {257},
pages = {104378},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104378},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001018},
author = {Weidong Zhang and Kang Cheng and Ying Liu and Yu Hao},
keywords = {Room layout estimation, Indoor reconstruction, Monocular depth estimation, Planar depth parameters},
abstract = {The room layout captures the global structure of an indoor scene. Estimating the 3D layout of a room from an RGB image requires recovering the spatial information of the dominant indoor planes. However, directly learning the plane parameters or layout depth map is inherently ill-posed and prone to errors. In this paper, we introduce a guided progressive learning framework that systematically builds layout understanding through progressively complex representations. Our approach first learns pixel-level plane embeddings to capture the positional information of the dominant planes within the room. Building on these embeddings, we then learn the planar depth parameters for each pixel. Using these parameters, we generate a coarse layout depth map through pixel-wise calculations. To enhance the accuracy of this depth map, we employ a refinement module that not only produces a refined layout depth map but also establishes geometric connections between the pixel-level outputs. During inference, we select the optimal layout hypothesis based on the predicted plane embeddings, planar depth parameters, and layout depth map. The proposed guided progressive learning framework achieves state-of-the-art performance on both 3D and 2D layout estimation metrics, demonstrating its robustness and precision.}
}