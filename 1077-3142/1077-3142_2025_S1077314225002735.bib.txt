@article{MAO2025104550,
title = {MSFENet: Multi-Scale Filter-Enhanced Network architecture for digital image forgery trace localization},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104550},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104550},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002735},
author = {Min Mao and Ge Jiao and Wanhui Gao and Jixun Ye},
keywords = {Image forgery localization, High-pass filter, Multi-scale feature extraction, Digital forensics, Feature fusion},
abstract = {With the rapid advancement of image editing technologies, forensic analysis for detecting malicious image manipulations has become a critical research topic. While existing deep learning-based forgery localization methods have demonstrated promising results, they face three fundamental limitations: (1) heavy reliance on large-scale annotated datasets, (2) computationally intensive training processes, and (3) insufficient capability in capturing diverse forgery traces. To address these challenges, we present MSFENet (Multi-Scale Filter-Enhanced Network), a novel framework that synergistically integrates multiple forensic filters for comprehensive forgery detection. Our approach introduces three key innovations: First, we employ a multi-filter feature extraction module that combines NoisePrint++, SRM, and Bayar Conv to capture complementary forensic traces, including noise patterns, texture inconsistencies, and boundary artifacts. Second, we introduce a dual-branch multi-scale encoder that effectively preserves both local and global manipulation characteristics. Third, we design two novel components: the Coordinate Attention-based Cross-modal Feature Rectification (CAFR) module, which adaptively recalibrates feature representations across different modalities and learns the complementary properties of different extracted features, and the Multi-Scale Selective Fusion (MSF) module, which intelligently integrates discriminative features while suppressing redundant information. Extensive experiments on six benchmark datasets demonstrate the superiority of MSFENet. Our method achieves state-of-the-art performance, with F1-score improvements of 6.36%, 0.84%, 6.22%, and 48.8% on Casiav1, COVER, IMD20, and DSO-1, respectively, compared to existing methods.}
}