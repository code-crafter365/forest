@article{ZHENG2025104489,
title = {LAM-YOLO: Drones-based small object detection on lighting-occlusion attention mechanism YOLO},
journal = {Computer Vision and Image Understanding},
volume = {261},
pages = {104489},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104489},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002127},
author = {Yuchen Zheng and Yuxin Jing and Jufeng Zhao and Guangmang Cui},
keywords = {Drone-based target detection, Dense packed objects, Attention mechanism, Auxiliary small target detection heads, YOLO (You only look once)},
abstract = {Drone-based target detection presents inherent challenges, including the high density and overlap of targets in drone images, as well as the blurriness of targets under varying lighting conditions, which complicates accurate identification. Traditional methods often struggle to detect numerous small, densely packed targets against complex backgrounds. To address these challenges, we propose LAM-YOLO, an object detection model specifically designed for drone-based applications. First, we introduce a light-occlusion attention mechanism to enhance the visibility of small targets under diverse lighting conditions. Additionally, we incorporate Involution modules to improve feature layer interactions. Second, we employ an improved SIB-IoU as the regression loss function to accelerate model convergence and enhance localization accuracy. Finally, we implement a novel detection strategy by introducing two auxiliary detection heads to better identify smaller-scale targets. Our quantitative results demonstrate that LAM-YOLO outperforms methods such as Faster R-CNN, YOLOv11, and YOLOv12 in terms of mAP@0.5 and mAP@0.5:0.95 on the VisDrone2019 public dataset. Compared to the original YOLOv8, the average precision increases by 7.1%. Additionally, the proposed SIB-IoU loss function not only accelerates convergence speed during training but also improves average precision compared to the traditional loss function.}
}