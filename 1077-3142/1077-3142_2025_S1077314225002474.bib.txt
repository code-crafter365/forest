@article{HU2025104524,
title = {Learning multiscale residual prototypes and global–local correspondence for video anomaly detection},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104524},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104524},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002474},
author = {Yongting Hu and Yuanhong Zhong and Jinkai Li and Xin Wang},
keywords = {Video anomaly detection, Memory network, Multiscale residual, Global–local correspondence},
abstract = {With the powerful generalization ability of deep learning, existing video anomaly detection methods based on reconstruction or prediction can reconstruct not only normal but also abnormal frames. In response to this issue, numerous methods have been suggested to learn prototypes of normal events to suppress the generalization ability of networks towards anomalies. However, the majority of prototypes in these methods are single-scaling, which leads to an incomplete representation of the intricate complexity of normal events. Additionally, current methods tend to overemphasize global information while neglecting the importance of local information and its correspondence with local information. To address the aforementioned issues, we propose to learn Multiscale Residual Prototypes and Global–Local Correspondence (MRP-GLC) for video anomaly detection. Specifically, we introduce a Multiscale Residual Prototypes Fusion (MRPF) module that enables the learning and integration of multi-scale prototypes of normal events. The utilization of a residual design in this module ensures that the prototypes of normal events are learned while retaining the respective properties of each individual normal event. To facilitate global–local feature correspondence, we adopt a dual-encoder architecture to learn both local and global features, which are subsequently aggregated through our global–local fusion module and fed into the decoder for future frame prediction. The global–local fusion module leverages global features to prioritize attention on local features, enabling the capture of correspondence between global and local information. Extensive experiments conducted on three public datasets demonstrate the effectiveness of the proposed method.}
}