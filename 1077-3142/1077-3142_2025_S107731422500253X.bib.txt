@article{YU2025104530,
title = {Dynamic deep multi-label image data augmentation based on self-paced learning},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104530},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104530},
url = {https://www.sciencedirect.com/science/article/pii/S107731422500253X},
author = {Bin Yu and Wei Li and Chen Zhang and Wenjie Mao and Yu Xie},
keywords = {Multi-label learning, Self-paced learning, Data augmentation, Oversampling, Synthetic Minority Oversampling Technique (SMOTE)},
abstract = {Multi-label classification is crucial in image recognition. However, data class imbalance can lead to poor performance in classification algorithms, particularly for minority classes, thereby impacting overall accuracy. Existing augmentation methods for minority class data typically adopt a dataset-wide approach, failing to enhance minority class samples based on the model’s performance for each class during training. In this paper, we propose an end-to-end Self-paced Deep Multi-label data Augmentation (SDMA) method which is capable of dynamically generating image data for minority classes in multi-label classification. Our method selects a batch of relatively simple samples as the training set during each training iteration. The number of samples from each category in this batch reflects the model’s training performance on those categories. By generating data for the minority classes within these samples, we can dynamically generate samples that better meet the model’s needs based on its training progress. Additionally, to mitigate the impact of noisy data in the generated set, we compute the predicted similarity of the generated data with the seed and reference instances, excluding low-similarity data from influencing the model. Extensive experiments on multi-label datasets demonstrate that SDMA is competitive compared to other state-of-the-art methods.}
}