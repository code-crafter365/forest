@article{PAN2025104497,
title = {Two-stage attribute-guided dual attention network for fine-grained fashion retrieval},
journal = {Computer Vision and Image Understanding},
volume = {261},
pages = {104497},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104497},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002206},
author = {Bo Pan and Jun Xiang and Ning Zhang and Ruru Pan},
keywords = {Fashion retrieval, Fine-grained similarity, Attribute guidance, Image retrieval},
abstract = {Fine-grained clothing retrieval is essential for intelligent shopping and personalized recommendation systems. However, conventional methods often fail to capture subtle attribute variations. This paper proposes a novel two-stage attribute-guided dual attention network. The network combines global and local feature extraction with Attribute-aware Multi-Scale Spatial Attention (AMSA) and Attribute-guided Dynamic Channel Attention (ADCA). AMSA captures attribute-specific spatial details at multiple scales, while ADCA dynamically adjusts channel importance based on attribute embeddings, enabling precise attribute-level similarity modeling. A multi-level joint loss function further optimizes both global and local representations and enhances feature alignment. Experiments on FashionAI and the self-built FGDress dataset show that the proposed method achieves mAP scores of 66.01% and 73.98%, respectively, outperforming baseline approaches. Attribute-level analysis confirms robust recognition of both well-defined and challenging attributes. These results validate the practicality and generalizability of the proposed framework, with promising applications in personalized recommendation, fashion trend analysis, and design evaluation.}
}