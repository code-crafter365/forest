@article{SI2025104360,
title = {Learning temporal-aware representation for controllable interventional radiology imaging},
journal = {Computer Vision and Image Understanding},
volume = {257},
pages = {104360},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104360},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225000839},
author = {Wei Si and Zhaolin Zheng and Zhewei Huang and Xi-Ming Xu and Ruijue Wang and Ji-Gang Bao and Qiang Xiong and Xiantong Zhen and Jun Xu},
keywords = {Video frame interpolation, Temporal-aware, Modeling, Implicit function, Interventional radiology imaging},
abstract = {Interventional Radiology Imaging (IRI) is essential for evaluating cerebral vascular anatomy by providing sequential images of both arterial and venous blood flow. In IRI, the low frame rate (4 fps) during acquisition can lead to discontinuities and flickering, whereas higher frame rates are associated with increased radiation exposure. Nevertheless, under complex blood flow conditions, it becomes necessary to increase the frame rate to 15 fps for the second sampling. Previous methods relied solely on fixed frame interpolation to mitigate discontinuities and flicker. However, owing to frame rate constraints, they were ineffective in addressing the high radiation issues arising from complex blood flow conditions. In this study, we introduce a novel approach called Temporally Controllable Network (TCNet), which innovatively applies controllable frame interpolation techniques to IRI for the first time. Our method effectively tackles the issues of discontinuity and flickering arising from low frame rates and mitigates the radiation concerns linked to higher frame rates during second sampling. Our method emphasizes synthesizing intermediate frame features via a Temporal-Aware Representation Learning (TARL) module and optimizes this process through bilateral optical flow supervision for accurate optical flow estimation. Additionally, to enhance the depiction of blood vessel motion and breathing nuances, we introduce an implicit function module for refining motion cues in videos. Our experiments reveal that TCNet successfully generate videos at clinically appropriate frame rates, significantly improving the reconstruction of blood flow and respiratory patterns. We will publicly release our code and datasets.}
}