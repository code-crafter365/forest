@article{GAO2025104426,
title = {FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition},
journal = {Computer Vision and Image Understanding},
volume = {259},
pages = {104426},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104426},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225001493},
author = {Gong Gao and Zekai Wang and Xianhui Liu and Weidong Zhao},
keywords = {Multi-task network, Face attribute recognition, Attribute group, Feature fusion, Dynamic weighting strategy},
abstract = {To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.}
}