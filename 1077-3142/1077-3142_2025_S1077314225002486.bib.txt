@article{XU2025104525,
title = {D2PCFN: Dual domain progressive cross-fusion network for remote sensing image pansharpening},
journal = {Computer Vision and Image Understanding},
volume = {262},
pages = {104525},
year = {2025},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2025.104525},
url = {https://www.sciencedirect.com/science/article/pii/S1077314225002486},
author = {Biyun Xu and Yan Zheng and Suleman Mazhar and Zhenghua Huang},
keywords = {Computer vision, Pansharpening, High-resolution multispectral (HRMS) images, Image fusion},
abstract = {High-resolution multispectral (HRMS) image generation through pansharpening requires effective integration of spatial details from panchromatic (PAN) images and spectral information from low-resolution multispectral (LRMS) images. Existing methods often overlook interactions between deep features across different depths and modalities, resulting in spectral distortion and loss of spatial detail. To address this, we propose a dual domain progressive cross-fusion network (D2PCFN) that progressively integrates features in both spatial and frequency domains. The network consists of a dual-branch feature generation module (DBFGM) for deep feature extraction, a dual domain cross-fusion module (D2CFM) for cross-interaction between spatial and frequency representations, and a deep feature reconstruction module (DFRM) for synthesizing high-quality outputs. Extensive experiments on GaoFen-2, QuickBird, WorldView-3, and WorldView-2 datasets demonstrate that our method achieves state-of-the-art accuracy, with average gains of 1.77% in SAM, 1.70% in ERGAS, 0.89% in PSNR, and 1.37% in HQNR over leading methods. Both quantitative and qualitative results confirm the effectiveness and generalization ability of the proposed D2PCFN. Source code will also be shared on https://github.com/MysterYxby/D2PCFN-website link after publication.}
}