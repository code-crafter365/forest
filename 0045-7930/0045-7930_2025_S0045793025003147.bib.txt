@article{KURZ2025106854,
title = {Invariant control strategies for active flow control using graph neural networks},
journal = {Computers & Fluids},
volume = {303},
pages = {106854},
year = {2025},
issn = {0045-7930},
doi = {https://doi.org/10.1016/j.compfluid.2025.106854},
url = {https://www.sciencedirect.com/science/article/pii/S0045793025003147},
author = {Marius Kurz and Rohan Kaushik and Marcel Blind and Patrick Kopper and Anna Schwarz and Felix Rodach and Andrea Beck},
keywords = {Active flow control, Machine learning, Graph neural networks, Reinforcement learning},
abstract = {Reinforcement learning (RL) has recently gained traction for active flow control tasks, with initial applications exploring drag mitigation via flow field augmentation around a two-dimensional cylinder. RL has since been extended to more complex turbulent flows and has shown significant potential in learning complex control strategies. However, such applications remain computationally challenging owing to its sample inefficiency and associated simulation costs. This fact is worsened by the lack of generalization capabilities of these trained policy networks, often being implicitly tied to the input configurations of their training conditions. In this work, we propose the use of graph neural networks (GNNs) to address this particular limitation, effectively increasing the range of applicability and getting more value out of the upfront RL training cost. GNNs can naturally process unstructured, three-dimensional flow data, preserving spatial relationships without the constraints of a Cartesian grid. Additionally, they incorporate rotational, reflectional, and permutation invariance into the learned control policies, thus improving generalization and thereby removing the shortcomings of commonly used convolutional neural networks (CNNs) or multilayer perceptron (MLP) architectures. To demonstrate the effectiveness of this approach, we revisit the well-established two-dimensional cylinder benchmark problem for active flow control. The RL training is implemented using Relexi, a high-performance RL framework, with flow simulations conducted in parallel using the high-order discontinuous Galerkin framework FLEXI. Our results show that GNN-based control policies achieve comparable performance to existing methods while benefiting from improved generalization properties. This work establishes GNNs as a promising architecture for RL-based flow control and highlights the capabilities of Relexi and FLEXI for large-scale RL applications in fluid dynamics.}
}